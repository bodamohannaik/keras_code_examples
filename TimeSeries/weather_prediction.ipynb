{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "weather_prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "KUWSXdJKbkky"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0BZr-pqZAMA"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download and Load DataSet"
      ],
      "metadata": {
        "id": "J53xOq9UbwNq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !curl -O https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip\n",
        "# !unzip jena_climate_2009_2016.csv.zip"
      ],
      "metadata": {
        "id": "sSc5odA5bu_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download file \n",
        "zip_path = tf.keras.utils.get_file(fname='jena_climate_2009_2016.csv', \n",
        "                        origin='https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip')\n",
        "zip_file = zipfile.ZipFile(file=zip_path, mode='r')\n",
        "zip_file.extractall()"
      ],
      "metadata": {
        "id": "6CAnb8iRDV4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_dataset = pd.read_csv('jena_climate_2009_2016.csv')"
      ],
      "metadata": {
        "id": "DAws7_G0GTZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Visualization"
      ],
      "metadata": {
        "id": "jIXKZ__Fp_sl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_dataset"
      ],
      "metadata": {
        "id": "t6T1HyMLHM1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check for null values\n",
        "raw_dataset.info()"
      ],
      "metadata": {
        "id": "LgVbEOiEORsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_dataset.describe()"
      ],
      "metadata": {
        "id": "UX0NAJR4Oe5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "col_short_description = {'Date Time': 'Date Time', \n",
        "                         'p (mbar)': 'Internal Presure', \n",
        "                         'T (degC)': 'Temperature in Celsius',\n",
        "                         'Tpot (K)': 'Temperature in Kelvin', \n",
        "                         'Tdew (degC)': 'Temperature in Celsius relative to humidity' , \n",
        "                         'rh (%)': 'Relative Humidity', \n",
        "                         'VPmax (mbar)': 'Saturation vapor pressure', \n",
        "                         'VPact (mbar)': 'Vapor pressure', \n",
        "                         'VPdef (mbar)': 'Vapor pressure deficit', \n",
        "                         'sh (g/kg)': 'Specific humidity', \n",
        "                         'H2OC (mmol/mol)': 'Water vapor concentration',\n",
        "                         'rho (g/m**3)': 'Airtight', \n",
        "                         'wv (m/s)': 'Wind Speed', \n",
        "                         'max. wv (m/s)': 'Maximum Wind Speed',\n",
        "                         'wd (deg)': 'Wind Direction in Degrees'}"
      ],
      "metadata": {
        "id": "6wacV0t0K5Bs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_features = ['p (mbar)',\n",
        " 'T (degC)',\n",
        " 'Tpot (K)',\n",
        " 'Tdew (degC)',\n",
        " 'rh (%)',\n",
        " 'VPmax (mbar)',\n",
        " 'VPact (mbar)',\n",
        " 'VPdef (mbar)',\n",
        " 'sh (g/kg)',\n",
        " 'H2OC (mmol/mol)',\n",
        " 'rho (g/m**3)',\n",
        " 'wv (m/s)',\n",
        " 'max. wv (m/s)',\n",
        " 'wd (deg)']"
      ],
      "metadata": {
        "id": "TlHqNtwMOGTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# box plot \n",
        "plt.figure(figsize = (20,15))\n",
        "for i in  range(len(numerical_features)):\n",
        "  ax = plt.subplot(3, 5, i+1)\n",
        "  ax.boxplot(raw_dataset[numerical_features[i]])\n",
        "  ax.set_title(col_short_description[numerical_features[i]])"
      ],
      "metadata": {
        "id": "UKmCe1INPUfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hist plot \n",
        "plt.figure(figsize = (20,15))\n",
        "for i in  range(len(numerical_features)):\n",
        "  ax = plt.subplot(3, 5, i+1)\n",
        "  ax.hist(raw_dataset[numerical_features[i]])\n",
        "  ax.set_title(col_short_description[numerical_features[i]])"
      ],
      "metadata": {
        "id": "sMgYYjNyaHxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  plot \n",
        "plt.figure(figsize = (20,15))\n",
        "for i in  range(len(numerical_features)):\n",
        "  ax = plt.subplot(3, 5, i+1)\n",
        "  ax.plot(raw_dataset[numerical_features[i]])\n",
        "  ax.set_title(col_short_description[numerical_features[i]])"
      ],
      "metadata": {
        "id": "K58cPWZNcGB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# heatmap\n",
        "corr = raw_dataset.corr()\n",
        "fig, axs = plt.subplots(figsize = (25,15))\n",
        "sns.heatmap(data = corr, annot =True, fmt ='.2f', annot_kws={'size':12})"
      ],
      "metadata": {
        "id": "qQqAhgwUhb6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Data"
      ],
      "metadata": {
        "id": "SQwtS9Xeqetr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# full dataset shape\n",
        "raw_dataset.shape"
      ],
      "metadata": {
        "id": "SmCVbxZfqgml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train , test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "raw_dataset_train, raw_dataset_test = train_test_split(raw_dataset, train_size =0.715)\n",
        "raw_dataset_train.shape, raw_dataset_test.shape"
      ],
      "metadata": {
        "id": "y6342PdT3lDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# select features to use for training and seperate out the labels\n",
        "features = ['p (mbar)',\n",
        " 'T (degC)',           \n",
        " 'Tpot (K)',\n",
        " 'Tdew (degC)',\n",
        " 'rh (%)',\n",
        " 'VPmax (mbar)',\n",
        " 'VPact (mbar)',\n",
        " 'VPdef (mbar)',\n",
        " 'sh (g/kg)',\n",
        " 'H2OC (mmol/mol)',\n",
        " 'rho (g/m**3)',\n",
        "  #  'wv (m/s)',\n",
        "  #  'max. wv (m/s)',\n",
        "  #  'wd (deg)'\n",
        "]\n",
        "# label of the model\n",
        "output_feature = ['T (degC)']\n",
        "\n",
        "def select_features(dataset):\n",
        "   return dataset.loc[:,features], dataset.loc[:, output_feature]\n",
        "dataset_train, output_train = select_features(dataset = raw_dataset_train)\n",
        "dataset_test, output_test = select_features(dataset = raw_dataset_test)\n",
        "dataset, output = select_features(dataset = raw_dataset)\n",
        "dataset.shape, output.shape, dataset_train.shape, output_train.shape, dataset_test.shape, output_test.shape"
      ],
      "metadata": {
        "id": "dRUlehUu5dR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# features scaling\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "in_scaler = MinMaxScaler()\n",
        "in_scaler.fit(dataset_train)\n",
        "def input_feature_scaling(dataset):\n",
        "  return in_scaler.transform(dataset)\n",
        "dataset_train_scaled = input_feature_scaling(dataset = dataset_train)\n",
        "dataset_test_scaled = input_feature_scaling(dataset=dataset_test)\n",
        "dataset_scaled = input_feature_scaling(dataset=dataset)\n",
        "dataset_train_scaled.shape, dataset_test_scaled.shape, dataset_scaled.shape"
      ],
      "metadata": {
        "id": "Hf-sxUqK37Pt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# output features scaling\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "out_scaler = MinMaxScaler()\n",
        "out_scaler.fit(output_train)\n",
        "def input_feature_scaling(dataset):\n",
        "  return out_scaler.transform(dataset)\n",
        "output_train_scaled = input_feature_scaling(dataset = output_train)\n",
        "output_test_scaled = input_feature_scaling(dataset = output_test)\n",
        "output_scaled = input_feature_scaling(dataset = output)\n",
        "output_train_scaled.shape, output_test_scaled.shape, output_scaled.shape"
      ],
      "metadata": {
        "id": "CZqwCrwo8UBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# every hour\n",
        "sampling_rate = 6\n",
        "# 5 days past history\n",
        "sequence_length = 5*24\n",
        "# predict weather after 12 hour\n",
        "predict_length = 12\n",
        "batch_size = 256\n",
        "# as we are using 5 days 12 hours gap between input and output lets slice the output\n",
        "output_start = sampling_rate*(sequence_length+predict_length)\n",
        "# trainsize - sequence_length*sampling_rate +1\n",
        "output_end = sampling_rate*(predict_length)+len(dataset_train_scaled)+1\n",
        "y_train = output_scaled[output_start:output_end, :]\n",
        "X_train = tf.keras.preprocessing.timeseries_dataset_from_array(data=dataset_train_scaled, targets = y_train,\n",
        "                                                               sequence_length = sequence_length, sampling_rate = sampling_rate,\n",
        "                                                               batch_size = batch_size) \n",
        "\n",
        "X_train.cardinality(), y_train.shape"
      ],
      "metadata": {
        "id": "mPhmxCXv8z3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# as we are using 5 days 12 hours gap between input and output lets slice the output\n",
        "output_start = sampling_rate*(sequence_length+predict_length)\n",
        "y_test = output_test_scaled[output_start:]\n",
        "X_test = tf.keras.preprocessing.timeseries_dataset_from_array(data=dataset_test_scaled, targets = y_test,\n",
        "                                                               sequence_length = sequence_length, sampling_rate = sampling_rate,\n",
        "                                                               batch_size = batch_size) \n",
        "\n",
        "X_test.cardinality(), y_test.shape"
      ],
      "metadata": {
        "id": "CGWzddsVn59e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "_udGSdguzB2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.layers.Input(shape= (sequence_length, len(features)))\n",
        "x = tf.keras.layers.LSTM(units =16)(inputs)\n",
        "x = tf.keras.layers.Dropout(rate = .5)(x)\n",
        "x = tf.keras.layers.Dense(units =1)(x)\n",
        "model = tf.keras.Model(inputs = inputs, outputs = x)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "7y30JRqgzAUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7f6CMAdd_3kd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss = 'mse', metrics = [tf.keras.metrics.RootMeanSquaredError()])"
      ],
      "metadata": {
        "id": "rM3KyR7WzspB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, epochs =5, validation_data = X_test)"
      ],
      "metadata": {
        "id": "f9I9-qysz16n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the train and test loss\n",
        "fig, axs = plt.subplots(figsize = (15,15))\n",
        "axs.plot(history.history['loss'], color ='b', label = 'training loss')\n",
        "axs.plot(history.history['val_loss'], color ='r', label ='test loss')\n",
        "axs.set_title('Training vs Test loss')\n",
        "axs.set_xlabel('epochs')\n",
        "axs.set_ylabel('mse')\n",
        "axs.legend()"
      ],
      "metadata": {
        "id": "ACBxJXbHz6Ub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the predictions\n",
        "for batch_features, batch_labels in X_test.take(5):\n",
        "  fig, axs = plt.subplots()\n",
        "  one_ts_observation = batch_features[0:1,]\n",
        "  prediction = model.predict(one_ts_observation)\n",
        "  plt.plot(predict_length, out_scaler.inverse_transform(prediction)[0,0], label ='prediction', marker ='x', color ='r', markersize = 16)\n",
        "  plt.plot(predict_length, out_scaler.inverse_transform(batch_labels)[0,0], label = 'actual', marker ='o', color ='g', markersize =16)\n",
        "  plt.plot(range(-sequence_length, 0), out_scaler.inverse_transform(one_ts_observation[0, :, 1:2])[:, 0], label ='past', color ='b')\n",
        "  fig.legend()\n"
      ],
      "metadata": {
        "id": "XypURGuF_4Zs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}